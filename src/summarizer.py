"""
Gemini APIã‚’ä½¿ç”¨ã—ã¦Kindleãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import logging
from typing import Optional

from google import genai
from google.genai import errors as genai_errors
from google.genai import types

from config import config

logger = logging.getLogger(__name__)

# Gemini APIç”¨ã®ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºï¼ˆå¤‰åŒ–åˆ†æç”¨ï¼‰
SYSTEM_INSTRUCTION_CHANGES = """
ã‚ãªãŸã¯Kindleé›»å­æ›¸ç±ã®å£²ã‚Œç­‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
å‰å›ã¨ä»Šå›ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æ¯”è¼ƒã—ã¦ã€é‡è¦ãªå¤‰åŒ–ã‚’3-4è¡Œã§å ±å‘Šã—ã¦ãã ã•ã„ã€‚

æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆï¼š
- æ–°è¦ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ä½œå“ã¨ãã®ç‰¹å¾´
- å¤§å¹…ãªé †ä½å¤‰å‹•ï¼ˆ3ä½ä»¥ä¸Šã®å¤‰åŒ–ï¼‰
- ã‚¸ãƒ£ãƒ³ãƒ«ã‚„ãƒ†ãƒ¼ãƒã®å¤‰åŒ–å‚¾å‘

çµµæ–‡å­—ã‚’ä½¿ã£ã¦èª­ã¿ã‚„ã™ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèˆˆå‘³ã‚’æŒã¦ã‚‹åˆ†æã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
"""

# Gemini APIç”¨ã®ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºï¼ˆåˆå›åˆ†æç”¨ï¼‰
SYSTEM_INSTRUCTION_FIRST = """
ã‚ãªãŸã¯Kindleé›»å­æ›¸ç±ã®å£²ã‚Œç­‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä»Šå›ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ç‰¹å¾´ã‚’3-4è¡Œã§åˆ†æã—ã¦ãã ã•ã„ã€‚

æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆï¼š
- ä¸Šä½ä½œå“ã®å‚¾å‘ã¨ã‚¸ãƒ£ãƒ³ãƒ«åˆ†å¸ƒ
- é«˜è©•ä¾¡ä½œå“ã‚„è©±é¡Œä½œã®å­˜åœ¨
- èª­è€…ã«å½¹ç«‹ã¤ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±

çµµæ–‡å­—ã‚’ä½¿ã£ã¦èª­ã¿ã‚„ã™ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ¬é¸ã³ã®å‚è€ƒã«ã§ãã‚‹åˆ†æã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
"""

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå¤‰åŒ–åˆ†æç”¨ï¼‰
PROMPT_TEMPLATE_CHANGES = """
å‰å›ã¨ä»Šå›ã®Kindleãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®å¤‰åŒ–ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€å¤‰åŒ–ã®å†…å®¹ã€‘
{changes_text}

ã€ä»Šå›ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€‘
{current_ranking}
"""

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆåˆå›åˆ†æç”¨ï¼‰
PROMPT_TEMPLATE_FIRST = """
Kindleãƒ©ãƒ³ã‚­ãƒ³ã‚°ä¸Šä½ã®å‚¾å‘ã‚’åˆ†æ:
{ranking_text}
"""


def _call_gemini_api(prompt: str, system_instruction: str) -> str:
    """
    Gemini APIã‚’å‘¼ã³å‡ºã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ

    Args:
        prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        system_instruction: ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º

    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ

    Raises:
        genai_errors.APIError: APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼
        ValueError: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã®å ´åˆ
    """
    client = genai.Client(api_key=config.gemini_api_key)

    response = client.models.generate_content(
        model=config.gemini_model,
        config=types.GenerateContentConfig(
            system_instruction=system_instruction, temperature=0.7, max_output_tokens=2000
        ),
        contents=prompt,
    )

    text_content = _extract_text_from_response(response)

    if not text_content:
        logger.error("Gemini APIã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        raise ValueError("Gemini APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")

    return text_content


def _extract_text_from_response(response) -> str | None:
    """
    Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º

    Args:
        response: Gemini APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹

    Returns:
        æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆå–å¾—ã§ããªã„å ´åˆã¯Noneï¼‰
    """
    # ç›´æ¥textãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
    if response.text:
        return response.text.strip()

    # candidatesã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    if hasattr(response, "candidates") and response.candidates:
        candidate = response.candidates[0]

        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
        if hasattr(candidate, "finish_reason"):
            logger.debug(f"finish_reason: {candidate.finish_reason}")

        if candidate.content and candidate.content.parts:
            text_parts = []
            for part in candidate.content.parts:
                if hasattr(part, "text") and part.text:
                    text_parts.append(part.text)

            if text_parts:
                return "".join(text_parts).strip()

    return None


def generate_ranking_changes_summary(changes_analysis: dict, current_ranking_text: str) -> Optional[str]:
    """
    Gemini APIã‚’ä½¿ã£ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®å¤‰åŒ–ã‚’è¦ç´„

    Args:
        changes_analysis: å¤‰åŒ–åˆ†æã®çµæœ
        current_ranking_text: ç¾åœ¨ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if not config.enable_gemini_summary or not config.gemini_api_key:
        logger.info("Geminiè¦ç´„ãŒç„¡åŠ¹ã¾ãŸã¯ã€APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None

    try:
        logger.info("Gemini APIã‚’ä½¿ç”¨ã—ã¦å¤‰åŒ–ã®è¦ç´„ã‚’ç”Ÿæˆä¸­...")

        # å¤‰åŒ–ã®å†…å®¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        changes_text = _format_changes_for_prompt(changes_analysis)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = PROMPT_TEMPLATE_CHANGES.format(changes_text=changes_text, current_ranking=current_ranking_text)

        # APIå‘¼ã³å‡ºã—
        summary = _call_gemini_api(prompt, SYSTEM_INSTRUCTION_CHANGES)

        logger.info(f"Geminiå¤‰åŒ–è¦ç´„ç”ŸæˆæˆåŠŸ: {len(summary)}æ–‡å­—")
        return summary

    except genai_errors.APIError as e:
        logger.error(f"Gemini APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None
    except ValueError as e:
        logger.error(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {str(e)}")
        return None


def generate_first_ranking_summary(ranking_text: str) -> Optional[str]:
    """
    Gemini APIã‚’ä½¿ã£ã¦åˆå›ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¦ç´„ã‚’ç”Ÿæˆ

    Args:
        ranking_text: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å–å¾—ã—ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿

    Returns:
        è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if not config.enable_gemini_summary or not config.gemini_api_key:
        logger.info("Geminiè¦ç´„ãŒç„¡åŠ¹ã¾ãŸã¯ã€APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None

    try:
        logger.info("Gemini APIã‚’ä½¿ç”¨ã—ã¦åˆå›è¦ç´„ã‚’ç”Ÿæˆä¸­...")

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã•ã‚ŒãŸä½æ•°ã«åˆ¶é™
        lines = ranking_text.split("\n")
        limited_lines = []
        count = 0
        for line in lines:
            if line.strip() and ("ä½|" in line):
                count += 1
                if count > config.gemini_summary_ranking_limit:
                    break
            limited_lines.append(line)
        limited_text = "\n".join(limited_lines)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = PROMPT_TEMPLATE_FIRST.format(ranking_text=limited_text)

        # APIå‘¼ã³å‡ºã—
        summary = _call_gemini_api(prompt, SYSTEM_INSTRUCTION_FIRST)

        logger.info(f"Geminiåˆå›è¦ç´„ç”ŸæˆæˆåŠŸ: {len(summary)}æ–‡å­—")
        return summary

    except genai_errors.APIError as e:
        logger.error(f"Gemini APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None
    except ValueError as e:
        logger.error(f"Gemini APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {str(e)}")
        return None


def _format_changes_for_prompt(analysis: dict) -> str:
    """
    å¤‰åŒ–åˆ†æçµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
    """
    lines = []

    if analysis["new_entries"]:
        lines.append("ã€æ–°è¦ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã€‘")
        for entry in analysis["new_entries"][:3]:  # ä¸Šä½3ã¤ã¾ã§
            lines.append(f"- {entry['rank']}ä½: {entry['title']}")

    if analysis["rank_changes"]:
        # å¤§ããªå¤‰å‹•ã®ã¿æŠ½å‡ºï¼ˆ3ä½ä»¥ä¸Šã®å¤‰å‹•ï¼‰
        big_changes = [c for c in analysis["rank_changes"] if abs(c["change"]) >= 3]
        if big_changes:
            lines.append("\nã€å¤§ããªé †ä½å¤‰å‹•ã€‘")
            for change in sorted(big_changes, key=lambda x: abs(x["change"]), reverse=True)[:3]:
                if change["change"] > 0:
                    lines.append(
                        f"- {change['title']}: {change['previous_rank']}ä½â†’{change['current_rank']}ä½ï¼ˆâ†‘{change['change']}ï¼‰"
                    )
                else:
                    lines.append(
                        f"- {change['title']}: {change['previous_rank']}ä½â†’{change['current_rank']}ä½ï¼ˆâ†“{abs(change['change'])}ï¼‰"
                    )

    if analysis["dropped_out"]:
        lines.append("\nã€ãƒ©ãƒ³ã‚¯å¤–ã€‘")
        for entry in analysis["dropped_out"][:2]:  # ä¸Šä½2ã¤ã¾ã§
            lines.append(f"- {entry['title']}ï¼ˆå‰å›{entry['previous_rank']}ä½ï¼‰")

    return "\n".join(lines)


def format_message_with_summary(ranking_text: str, summary: Optional[str] = None) -> str:
    """
    ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨è¦ç´„ã‚’çµ„ã¿åˆã‚ã›ã¦æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ

    Args:
        ranking_text: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§å–å¾—ã—ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
        summary: Geminiç”Ÿæˆã®è¦ç´„ï¼ˆNoneã®å ´åˆã¯è¦ç´„ãªã—ï¼‰

    Returns:
        æœ€çµ‚çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if summary:
        return f"{summary}\n\n---\n\n{ranking_text}"
    else:
        return ranking_text


def format_summary_only_message(summary: Optional[str] = None) -> str:
    """
    è¦ç´„ã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ

    Args:
        summary: Geminiç”Ÿæˆã®è¦ç´„ï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰

    Returns:
        è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚­ã‚¹ãƒˆ
    """
    if summary:
        return f"ğŸ“š **ä»Šæ—¥ã®Kindleãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ**\n\n{summary}"
    else:
        return "ğŸ“š **ä»Šæ—¥ã®Kindleãƒ©ãƒ³ã‚­ãƒ³ã‚°**"
